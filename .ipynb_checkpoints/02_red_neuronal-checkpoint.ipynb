{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Red neuronal multicapa en PyTorch\n",
    "\n",
    "En este notebook veremos como implementar una red neuronal usando PyTorch. En particular, implementaremos un perceptrón multicapa (MLP por sus siglas en inglés) para la classificación de dígitos del conjunto de datos MNIST.\n",
    "\n",
    "[![Open In Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/irvingvasquez/practicas_pytorch/blob/master/02_red_neuronal.ipynb)\n",
    "\n",
    "@juan1rving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Primero llamamos a los paquetes necesarios\n",
    "%matplotlib inline\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "\n",
    "import helper\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from torchvision import datasets, transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conjunto de datos\n",
    "\n",
    "Para la práctica necesitaremos un conjunto de datos (dataset). Afortunadamente el paquete **torchvision** provee diversos conjuntos de datos de ejemplo. En este ejercicio, utilizaremos MNIST, el cual contiene ejemplos de letras escritas a mano. El siguiente código lee el conjunto de datos y lo separa en un conjunto de entrenamiendo y uno de prueba. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generaramos una transformación para normalizar el conjunto de datos\n",
    "transform = transforms.Compose([transforms.ToTensor(),\n",
    "                              #transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5)),\n",
    "                               transforms.Normalize([0.5],[0.5]) \n",
    "                             ])\n",
    "# Descargamos el conjunto de datos de entrenamiento\n",
    "trainset = datasets.MNIST('MNIST_data/', download=True, train=True, transform=transform)\n",
    "# Cargamos el conjunto\n",
    "batch_size=64\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)\n",
    "\n",
    "# Descargamos y cargamos el conjunto de prueba\n",
    "testset = datasets.MNIST('MNIST_data/', download=True, train=False, transform=transform)\n",
    "testloader = torch.utils.data.DataLoader(testset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ordenamos los datos para tener parejas de imágenes con su respectiva clase\n",
    "\n",
    "# Los datos se encuentran en trainloader asi que generamos un iterador para extraerlos uno por uno\n",
    "dataiter = iter(trainloader)\n",
    "\n",
    "# TODO: Obtén un lote de ejemplos y sus respectivas etiquetas\n",
    "images, labels = next(dataiter)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Es recomendable verificar que estamos cargando bien el conjunto de datos. Asi que a continuación imprimeremos uno."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 28, 28])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "image/png": {
       "height": 248,
       "width": 251
      },
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(images[1].numpy().squeeze(), cmap='Greys_r');\n",
    "images[1].size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implementación de la red neuronal multicapa\n",
    "\n",
    "Ahora pasaremos a la creación de la red neuronal, como ejemplo utilizaremos un perceptrón multicapa para clasificar las imagenes del conjunto MNIST. Como entrada tendremos 784 nodos = 28 * 28, en seguida tendremos una capa oculta de 128 nodos, con una función de activación tipo RELU, despúes tendremos una segunda capa oculta con 64 nodos y función de activación RELU, en seguida tendremos 10 nodos de salida los cuales pasan por una función softmax que convierte los valores a probabilidades. En el siguiente ejercicio incluiremos la pérdida (loss) con la función de entropía cruzada. \n",
    "\n",
    "<img src=\"archivos/net.png\">\n",
    "\n",
    "El modulo que contiene las herramientas para crear la RN es **pytorch.nn**. La red neuronal en sí se crea como una clase que hereda la estructura de **pytorch.nn.Module**. Cada una de las capas de la red se define de forma independiente. e.g. Para crear una capa con 784 entradas y 128 nodos utilizamos *nn.Linear(784, 128)*\n",
    "\n",
    "La red implementa la función *forward* que realiza el paso frontal (fowdward pass). Esta función miembro recibe un tensor como entrada y calcula la salida de la red.\n",
    "\n",
    "Varias funciones de activación se encuntran en el módulo *nn.functional*. Dicho módulo usualmente se importa como *F*. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# importamos paquetes de pytorch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "En general las redes implementan a partir de la clase nn.Module que provee la clase base. Por lo tanto en este ejercicio declararemos una clase denominada red neuronal que hereda de nn.Module.  Una vez declarada nuestra red neuronal es necesario includir como atributos de la case las capas que se requieren, esto por que cada capa incluye los parámetros (pesos) que se entrenarán y deben tener permanencia mientras exista la red. Dichas capas se incluirán dentro del constructor __init__ . \n",
    "\n",
    "De acuerdo a pytorch.org\n",
    "\n",
    "    nn.Linear(in_features, out_features, bias=True, device=None, dtype=None)\n",
    "\n",
    "Applies a linear transformation to the incoming data.\n",
    "\n",
    "Por lo tanto si queremos uncluir una sola capa podríamos codificar lo siguiente:\n",
    "\n",
    "    self.fc = nn.Lnear(n_inputs, n_outputs)\n",
    "\n",
    "A continuación definiremos el comportamiento de inferencia de la red dentro de la funcion forward. En el comportamiento indicaremos el orden en el que se van ejecutando las capas y las funciones de activación. Recuerda que las funciones de activación solo se llaman pero no se instancían. Un ejemplo de una sola capa sería:\n",
    "\n",
    "    def forward(self, x):\n",
    "        y = F.relu(self.fc(x))\n",
    "        return y\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Implementación de la red neuronal\n",
    "class RedNeuronal(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        # TODO: Definir las capas. Cada una con 128, 64 y 10 unidades respectivamente\n",
    "        self.fc1 = None\n",
    "        self.fc2 = None\n",
    "        self.fc3 = None\n",
    "        \n",
    "    def forward(self, x):\n",
    "        ''' Pase frontal de la red, regresamos las probabilidades '''\n",
    "        # TODO: Define el comportamiento de inferencia, Recuerda que al final esta función debe retornar probabilidades y no logits.\n",
    "        y = None\n",
    "\n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RedNeuronal()\n"
     ]
    }
   ],
   "source": [
    "model = RedNeuronal()\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inicializamos pesos y sesgos\n",
    "\n",
    "Cuando creas las capas se crean también los tensores correspondientes a los pesos y sesgos. Éstos son inicializados por ti, aunque pudes modificarlos usando funciones extra. Para observar sus valores puedes llamar a *model.fc1.weight* \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(model.fc1.weight)\n",
    "print(model.fc1.bias)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Supongamos que deseamos inicializar los pesos con algunos valores personalizados. Dado que los pesos y sesgos en sí son variables de autograd (Preparadas para el cálculo del gradiente automático) estos solo se pueden modificar cuando no estan en modo de autogradiente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Colocamos ceros\n",
    "model.fc1.bias.data.fill_(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# muestreamos desde una distribución normal con media cero y desv. estandar = 0.01\n",
    "model.fc1.weight.data.normal_(std=0.01)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Pase frontal\n",
    "\n",
    "Hasta el momento la red no está entrenada y solo tenemos los pesos aleatorios. Hagamos un pase frontal para ver que pasa. Primero debemos convertir la imagen a un tensor y pasarla a través de la red. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "# Obtengamos el siguiente lote de imágenes\n",
    "#dataiter = iter(trainloader)\n",
    "images, labels = dataiter.next()\n",
    "\n",
    "# Reestructuremos el lote a un vector de una dimensión, hay quien le llama a esta operación \"aplanado\".\n",
    "# La nueva forma será (batch size, color channels, image pixels) \n",
    "images.resize_(batch_size, 1, 784)\n",
    "# alternativa: images.resize_(images.shape[0], 1, 784) to not automatically get batch size\n",
    "\n",
    "# Pase frontal de la red\n",
    "img_idx = 0\n",
    "prediction = model.forward(images[img_idx,:])\n",
    "\n",
    "print(prediction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "img = images[img_idx]\n",
    "helper.view_classify(img.view(1, 28, 28), prediction)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Seguro ninguna de las clases tiene una probabilidad grande con respecto de las otras, esto se debe a que todavía no hemos entrenado la red. En el siguiente ejercicio entrenaremos la red.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "practicas_pt",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "e22d029f5570ef7df543599926afc42bb090457ba5a887f8aae20fd6018d0da0"
   }
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
